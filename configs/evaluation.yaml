# Evaluation task configurations

# Contextual knowledge tasks
contextual_tasks:
  passkey_retrieval:
    description: "Retrieve passkey from long context"
    metric: "accuracy"
    context_lengths: [512, 1024, 2048, 4096]
    depths: [10, 25, 50, 75, 90]
    num_samples: 100
    passkey_length: 5

  imdb:
    description: "Sentiment classification"
    dataset: "imdb"
    split: "test"
    metric: "accuracy"
    max_samples: 1000
    prompt_template: |
      Review: {text}
      Sentiment (positive or negative):

  gsm8k:
    description: "Grade school math word problems"
    dataset: "gsm8k"
    config: "main"
    split: "test"
    metric: "accuracy"
    max_samples: 500
    prompt_template: |
      Question: {question}
      Let's solve this step by step.
      Answer:

  aqua:
    description: "Algebraic word problems"
    dataset: "aqua_rat"
    split: "test"
    metric: "accuracy"
    max_samples: 200

# Parametric knowledge tasks
parametric_tasks:
  cities:
    description: "Location verification"
    dataset: "cities"
    metric: "accuracy"
    max_samples: 500
    prompt_template: |
      Is {city} located in {country}? Answer yes or no.

  sports:
    description: "Sports factual QA"
    metric: "accuracy"
    max_samples: 200

  celebrity:
    description: "Celebrity factual QA"
    metric: "accuracy"
    max_samples: 200

# Generation quality metrics
generation_metrics:
  perplexity:
    stride: 512
    max_length: 2048

  diversity:
    ngrams: [2, 3]
    num_samples: 100
    max_new_tokens: 100
    temperature: 0.7
